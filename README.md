# Sativa
Evaluating patterns for optimizing data locality in HPC nodes for large-scale data analysis/machine learning tasks.

# Background
Tasks executed in an HPC node need access data but accessing data from the shared file system (e.g., Lustre) might be slow. Patterns for data coupling and movement between HPC storage/outside cloud and local nodes will be evaluated and suggested (e.g. with different HPC systems in Aalto/CSC)

# Link
- Examine data movement techniques between/within HPC/Cloud: reactive data movement, scheduled movement or incremental data movement
- Build examples of data movement tasks and couple them into the data analytics
- Using CSC Allas/Cloud storage and CSC Supercomputing/HPC
- Application/data: potentially ML/e-science (dependent on student experiences)

# Project Plan
#### Week 1:
- Choose a background theme and a specific problem for the project.
- Learn about data movement problem in cloud and HPC environment in general.
- Review current data locality and movement techniques in cloud and HPC.
- Review related tools suitable for implementing the project.

#### Week 2 & 3:
- Setup tools for development and experiment.
- Implement functions/features/pipelines/components for evaluating data locality and   
- Run experiment and record result.
- Extend the project if possible.

#### Week 4:
- Finalize experiment and implement demo.
- Finalize github repository with full documentation.
- Prepare representation
